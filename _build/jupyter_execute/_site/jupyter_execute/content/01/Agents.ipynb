{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhzCZ0I5GY3q"
   },
   "source": [
    "# Agents\n",
    "* Robot: simulated\n",
    "* Sensor: noisy state\n",
    "* Think: plan, Markov localization, RL\n",
    "* Act: Discrete\n",
    "* Topics needed: RL graphs & KF\n",
    "* Factor graph concepts: planning, markov localization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-X8s5UZaZc2"
   },
   "source": [
    "## Discrete States and Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x1QDeESJaZc3"
   },
   "source": [
    "## Classical Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qUYcGjLGTaQ"
   },
   "source": [
    "## MDP\n",
    "A Markov decision process (MDP) has states $x$ and actions $a$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5BtAxD9G2Au"
   },
   "source": [
    "## Reinforcement Learning "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02-DuckieBot2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}