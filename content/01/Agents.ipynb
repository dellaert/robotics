{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-DuckieBot2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dhzCZ0I5GY3q"
      },
      "source": [
        "# Agents\n",
        "* Robot: simulated\n",
        "* Sensor: noisy state\n",
        "* Think: plan, Markov localization, RL\n",
        "* Act: Discrete\n",
        "* Topics needed: RL graphs & KF\n",
        "* Factor graph concepts: planning, markov localization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-X8s5UZaZc2",
        "colab_type": "text"
      },
      "source": [
        "## Discrete States and Actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1QDeESJaZc3",
        "colab_type": "text"
      },
      "source": [
        "## Classical Planning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4qUYcGjLGTaQ"
      },
      "source": [
        "## MDP\n",
        "A Markov decision process (MDP) has states $x$ and actions $a$..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K5BtAxD9G2Au"
      },
      "source": [
        "## Reinforcement Learning "
      ]
    }
  ]
}